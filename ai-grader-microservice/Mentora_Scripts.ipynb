{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YakshithK/mentora/blob/yakshith%2Fai-grader/ai-grader-microservice/Mentora_Scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EnWCtSZhyJW",
        "outputId": "25afe60a-7b2a-43d4-d9b0-17f887450b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " loading file...\n",
            "loaded 4918 essays.\n",
            "loading model...\n",
            "🚀 Model loaded on: cpu\n",
            "starting grading...\n",
            "processed 0/4918 essays...\n",
            "processed 50/4918 essays...\n",
            "processed 100/4918 essays...\n",
            "processed 150/4918 essays...\n",
            "processed 200/4918 essays...\n",
            "processed 250/4918 essays...\n",
            "processed 300/4918 essays...\n",
            "processed 350/4918 essays...\n",
            "processed 400/4918 essays...\n",
            "processed 450/4918 essays...\n",
            "processed 500/4918 essays...\n",
            "processed 550/4918 essays...\n",
            "processed 600/4918 essays...\n",
            "processed 650/4918 essays...\n",
            "processed 700/4918 essays...\n",
            "processed 750/4918 essays...\n",
            "processed 800/4918 essays...\n",
            "processed 850/4918 essays...\n",
            "processed 900/4918 essays...\n",
            "processed 950/4918 essays...\n",
            "processed 1000/4918 essays...\n",
            "processed 1050/4918 essays...\n",
            "processed 1100/4918 essays...\n",
            "processed 1150/4918 essays...\n",
            "processed 1200/4918 essays...\n",
            "processed 1250/4918 essays...\n",
            "processed 1300/4918 essays...\n",
            "processed 1350/4918 essays...\n",
            "processed 1400/4918 essays...\n",
            "processed 1450/4918 essays...\n",
            "processed 1500/4918 essays...\n",
            "processed 1550/4918 essays...\n",
            "processed 1600/4918 essays...\n",
            "processed 1650/4918 essays...\n",
            "processed 1700/4918 essays...\n",
            "processed 1750/4918 essays...\n",
            "processed 1800/4918 essays...\n",
            "processed 1850/4918 essays...\n",
            "processed 1900/4918 essays...\n",
            "processed 1950/4918 essays...\n",
            "processed 2000/4918 essays...\n",
            "processed 2050/4918 essays...\n",
            "processed 2100/4918 essays...\n",
            "processed 2150/4918 essays...\n",
            "processed 2200/4918 essays...\n",
            "processed 2250/4918 essays...\n",
            "processed 2300/4918 essays...\n",
            "processed 2350/4918 essays...\n",
            "processed 2400/4918 essays...\n",
            "processed 2450/4918 essays...\n",
            "processed 2500/4918 essays...\n",
            "processed 2550/4918 essays...\n",
            "processed 2600/4918 essays...\n",
            "processed 2650/4918 essays...\n",
            "processed 2700/4918 essays...\n",
            "processed 2750/4918 essays...\n",
            "processed 2800/4918 essays...\n",
            "processed 2850/4918 essays...\n",
            "processed 2900/4918 essays...\n",
            "processed 2950/4918 essays...\n",
            "processed 3000/4918 essays...\n",
            "processed 3050/4918 essays...\n",
            "processed 3100/4918 essays...\n",
            "processed 3150/4918 essays...\n",
            "processed 3200/4918 essays...\n",
            "processed 3250/4918 essays...\n",
            "processed 3300/4918 essays...\n",
            "processed 3350/4918 essays...\n",
            "processed 3400/4918 essays...\n",
            "processed 3450/4918 essays...\n",
            "processed 3500/4918 essays...\n",
            "processed 3550/4918 essays...\n",
            "processed 3600/4918 essays...\n",
            "processed 3650/4918 essays...\n",
            "processed 3700/4918 essays...\n",
            "processed 3750/4918 essays...\n",
            "processed 3800/4918 essays...\n",
            "processed 3850/4918 essays...\n",
            "processed 3900/4918 essays...\n",
            "processed 3950/4918 essays...\n",
            "processed 4000/4918 essays...\n",
            "processed 4050/4918 essays...\n",
            "processed 4100/4918 essays...\n",
            "processed 4150/4918 essays...\n",
            "processed 4200/4918 essays...\n",
            "processed 4250/4918 essays...\n",
            "processed 4300/4918 essays...\n",
            "processed 4350/4918 essays...\n",
            "processed 4400/4918 essays...\n",
            "processed 4450/4918 essays...\n",
            "processed 4500/4918 essays...\n",
            "processed 4550/4918 essays...\n",
            "processed 4600/4918 essays...\n",
            "processed 4650/4918 essays...\n",
            "processed 4700/4918 essays...\n",
            "processed 4750/4918 essays...\n",
            "processed 4800/4918 essays...\n",
            "processed 4850/4918 essays...\n",
            "processed 4900/4918 essays...\n",
            "writing csv files...\n",
            "done! files saved: training.csv and testing.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(\" loading file...\")\n",
        "with open('leaf.jsonl', 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "data = []\n",
        "for line in lines:\n",
        "    obj = json.loads(line)\n",
        "    data.append({\n",
        "        'split': obj['split'],\n",
        "        'essay_text': obj['essay_text'],\n",
        "        'human_feedback': obj['human_feedback_text']\n",
        "    })\n",
        "\n",
        "print(f\"loaded {len(data)} essays.\")\n",
        "\n",
        "print(\"loading model...\")\n",
        "model_name = \"KevSun/Engessay_grading_ML\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"🚀 Model loaded on: {device}\")\n",
        "\n",
        "def get_grades(text):\n",
        "    if not text or not isinstance(text, str) or text.strip() == \"\":\n",
        "        return [1.0] * 6  # Default fail-safe values\n",
        "    encoded_input = tokenizer(\n",
        "        text, return_tensors='pt', padding=True, truncation=True, max_length=64\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_input)\n",
        "\n",
        "    predictions = outputs.logits.squeeze().cpu().numpy()\n",
        "    item_names = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n",
        "    scaled_scores = 2.25 * predictions - 1.25\n",
        "    rounded_scores = [round(score * 2) / 2 for score in scaled_scores]\n",
        "    return rounded_scores\n",
        "\n",
        "print(\"starting grading...\")\n",
        "for i, item in enumerate(data):\n",
        "    essay = item['essay_text']\n",
        "    scores = get_grades(essay)\n",
        "    item['grade'] = scores\n",
        "    if i % 50 == 0:\n",
        "        print(f\"processed {i}/{len(data)} essays...\")\n",
        "\n",
        "\n",
        "def write_csv(filtered_data, filename):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
        "        fieldnames = ['essay_text', 'human_feedback', 'grade']\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for row in filtered_data:\n",
        "            # Only keep expected fields\n",
        "            cleaned_row = {key: row[key] for key in fieldnames}\n",
        "            writer.writerow(cleaned_row)\n",
        "\n",
        "\n",
        "train_data = [d for d in data if d['split'] == 'train']\n",
        "test_data  = [d for d in data if d['split'] == 'test']\n",
        "\n",
        "print(\"writing csv files...\")\n",
        "write_csv(train_data, 'training.csv')\n",
        "write_csv(test_data, 'testing.csv')\n",
        "\n",
        "print(\"done! files saved: training.csv and testing.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6XxYN7OkwW84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6925b77a-3c55-4123-e344-e5583cf689a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m770.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch pandas scikit-learn --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "319e0XA_wbCk"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oXMq8SLAwdgn"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"training.csv\").dropna(subset=[\"essay_text\", \"human_feedback\"]).head(150)\n",
        "test_df = pd.read_csv(\"testing.csv\").dropna(subset=[\"essay_text\", \"human_feedback\"]).head(150)\n",
        "\n",
        "train_df[\"grading_pattern\"] = train_df[\"human_feedback\"].apply(\n",
        "    lambda f: \"Extract and list specific rubric-based patterns the teacher follows. For example:\\n- Strict on thesis clarity\\n- Tolerant of minor grammar errors\\n- Values personal voice\\nFeedback: \" + f\n",
        ")\n",
        "\n",
        "test_df[\"grading_pattern\"] = test_df[\"human_feedback\"].apply(\n",
        "    lambda f: \"Extract and list specific rubric-based patterns the teacher follows. For example:\\n- Strict on thesis clarity\\n- Tolerant of minor grammar errors\\n- Values personal voice\\nFeedback: \" + f\n",
        ")\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"essay_text\", \"grading_pattern\"]])\n",
        "test_dataset = Dataset.from_pandas(test_df[[\"essay_text\", \"grading_pattern\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "3570a444f7cf4c72969271ac5502aa97",
            "8bb31ccd02ee4e948510b2afd6c273ed",
            "414f851996ae437c842b7b77a3926499",
            "a53b962e16af4a36b5721139ea4f7500",
            "c83052d759734d41983f1b630ee4ed0c",
            "31bcf2e1fca744b9a5a8b3edcea45526",
            "bd80390a86da48478ecd931482c1af79",
            "92e2d0ecbec34311aef19a5fc1265de4",
            "77454980332747b6ba7863133a697a2d",
            "df22dbe58803444596ff4182df6253f1",
            "52dca939fa114d4780603b52516ee0de",
            "ae770935066141c4ac704dffd2086e73",
            "cccfaa3037a8456d9423b22d0d7e7b7e",
            "dbf1516b704349e4aedb288e3d7a5299",
            "29764b355ca44078bac81da3580839fc",
            "23077d5107304ef5b8086d1e6e397614",
            "f57b713c537a48d7ab239b6992f03321",
            "e8fe230242f249e9b24ad382af969e02",
            "9beb26ed00cc4c68885cfea2c8380875",
            "729a7e5303d14bfbb256df6b89777c6a",
            "be4ad994092e492bb3c17457ce35bb28",
            "5289f6c3cc05404dbecb72f809d50040"
          ]
        },
        "id": "dXXhIhn7whKj",
        "outputId": "747cea7d-2a0d-4424-9e50-9a7cb1a169d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3570a444f7cf4c72969271ac5502aa97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae770935066141c4ac704dffd2086e73"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_checkpoint = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 256\n",
        "\n",
        "def preprocess(example):\n",
        "    inputs = tokenizer(example[\"essay_text\"], truncation=True, padding=\"max_length\", max_length=max_input_length)\n",
        "    targets = tokenizer(example[\"grading_pattern\"], truncation=True, padding=\"max_length\", max_length=max_target_length)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "train_tokenized = train_dataset.map(preprocess, remove_columns=train_dataset.column_names)\n",
        "test_tokenized = test_dataset.map(preprocess, remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fr-PrQOBwjv5"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "06c34ca65d974f9ca9efda8fa9d314e8",
            "95cc48355ed74d839495a06d8d271922",
            "1fea597f40f04c93ae911c36206d609b",
            "d4673fd5ef8541ad96beba7bdaf2d6e8",
            "785b533be3624bb98d0e73acac97afea",
            "3e437c1c104648159ba50812b7efb49d",
            "94e489f3e89d4c308b3faf53c847ff25",
            "e1ea0991a9b14dd59c8b0a1ca44cbb22",
            "35e4b2631c46449b8e316716a6b3d094",
            "8210ea0020d946379f7d29c5d3cc8356",
            "ac4eaab3e6234a2bbe87e956004939ed",
            "79c333f457de40bc8c02f314ca23dca2",
            "6f16e50d02284fcaa08ed95a18d3aad9",
            "ad08deb5f4a24f30a68e6fe39e254e78",
            "f0923694ad8c4090967ca25a0922c08f",
            "bc78b07800874dc8be704d81bcc7330b",
            "34cecc6eb5814c55a16fc5f01ec3428e",
            "e065dc22c00a40639fd25236beed9a82",
            "e5c8a659eb3348d093264f9728f40ce6",
            "a1d451f5aa1f48f1bb89f032ecd7caa1"
          ]
        },
        "id": "Bz8O2DaSCuln",
        "outputId": "bb5629ce-17e3-44a7-b242-656ecf44c394"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06c34ca65d974f9ca9efda8fa9d314e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Gx706WNAwmFH"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./flan-t5-feedback\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=test_tokenized,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "nwihjdsOBitn",
        "outputId": "b190b16a-27aa-4cd9-9f18-e4b0d6f9d774"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-3ae0c60a1d7d>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 27:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.153334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.661808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.676600</td>\n",
              "      <td>3.536682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=114, training_loss=4.581195530138518, metrics={'train_runtime': 1651.476, 'train_samples_per_second': 0.272, 'train_steps_per_second': 0.069, 'total_flos': 83650727116800.0, 'train_loss': 4.581195530138518, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_insights(essay):\n",
        "    inputs = tokenizer(essay, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_input_length)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "sample_essay = test_df.iloc[0][\"essay_text\"]\n",
        "print(generate_insights(sample_essay))\n",
        "print(sample_essay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THM6o26gB_ud",
        "outputId": "768b6e9b-5008-4611-c95b-c7e752c7db47"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On the one hand, many people tend to repeat the same things as they believe they have achieved some security. However, change is not always a personal option. Even when people believe they are resisting change themselves, they cannot stop the world around them from changing. For instance, technology and scientific breakthroughs are changing the world on a daily basis. n On the other hand, I believe that change brings positive consequences for people. To give one example, repeating one job may be too tedious, and change can help people to have motivation for working. However, change is not always for the better. A lot of innovations, for example, are made with the aim of making money. In that case, new things should not be promoted. As a result, people need to keep pace with changes. n On the whole, I believe that people should not remain to do the same things, although all change does not necessarily have good outcomes. n On the whole, I believe that people should not remain to do the same things, although all change does not necessarily have good outcomes. n On the whole, I believe that people should not remain to do the same things, although all change does not necessarily have good outcomes.\n",
            "People have different views about the question of whether they should change or not. While many people persist in doing one thing in their whole life, personally I argue that change is an unavoidable thing in our life. \\n On the one hand, many people tend to repeat the same things as they believe they have achieved some security. However, change is not always a personal option. Even when people believe they are resisting change themselves, they cannot stop the world around them from changing. For instance, technology and scientific breakthroughs are changing the world on a daily basis. Another example would be that some people do not want to change their jobs because they are familiar with their current work and their colleagues. If they work in another workplace, they need to adapt a new environment, and they cannot concentrate on their work. Sooner or later, however, they would find that the familiar jobs no longer exist, or that the safety behaviours are no longer appropriate. \\n On the other hand, I believe that change brings positive consequences for people. To give one example, repeating one job may be too tedious, and change can help people to have motivation for working. However, change is not always for the better. A lot of innovations, for example, are made with the aim of making money. In that case new things should not be promoted. As a result, people need to keep pace with changes. \\n On the whole, I believe that people should not remain to do the same things, although all change does not necessarily have good outcomes. \\n ----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and tokenizer to a folder inside your Colab environment\n",
        "model.save_pretrained(\"./my-fine-tuned-model\")\n",
        "tokenizer.save_pretrained(\"./my-fine-tuned-model\")"
      ],
      "metadata": {
        "id": "xBktmBqc6st6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(\"my-fine-tuned-model\", 'zip', \"./my-fine-tuned-model\")"
      ],
      "metadata": {
        "id": "W_eEBAWhEkki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zipped model folder\n",
        "files.download(\"my-fine-tuned-model.zip\")"
      ],
      "metadata": {
        "id": "IPlvk9S3Emi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sIemWYiJzA-H",
        "outputId": "3a6ffa37-9ce3-4911-fccb-5663ab6fcb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (955.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m549.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 sympy-1.13.3 torch-2.7.0+cu118 torchaudio-2.7.0+cu118 torchvision-0.22.0+cu118 triton-3.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchgen"
                ]
              },
              "id": "88fb2000bc5042079933828d6d8b9abf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Input: Essay feedback samples\n",
        "feedback_sentences = [\n",
        "    \"Dear student, your discussion would have been better if you had tried to follow the proper discussion outline as indicated in the original prompt.\",\n",
        "    \"You neglected to properly assess the requirements of the essay and represent it in your outline plus paragraph discussion.\",\n",
        "    \"You were asked to discuss 2 points of view and then your personal opinion. You only discussed one point of view and your opinion.\",\n",
        "    \"In terms of task accuracy, that would result in a score of 4 because your response to the required discussion is minimal.\",\n",
        "    \"The failure of your opening statement, the paraphrasing sealed the failing score for your TA portion.\"\n",
        "]\n",
        "\n",
        "teacher_ids = [\"teacher_A\"] * len(feedback_sentences)\n",
        "\n",
        "# 2. Train BERTopic model\n",
        "topic_model = BERTopic(umap_model=None)\n",
        "topics, probs = topic_model.fit_transform(feedback_sentences)\n",
        "\n",
        "# 3. Analyze topic labels\n",
        "topic_info = topic_model.get_topic_info()\n",
        "print(\"\\n=== Topic Labels ===\")\n",
        "print(topic_info)\n",
        "\n",
        "# 4. Classify feedback as strict or not (you can replace this with ML)\n",
        "sentiments = [\n",
        "    \"strict\" if any(word in sent.lower() for word in [\"better\", \"neglected\", \"failing\"]) else \"neutral\"\n",
        "    for sent in feedback_sentences\n",
        "]\n",
        "\n",
        "# 5. Create full DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"teacher\": teacher_ids,\n",
        "    \"sentence\": feedback_sentences,\n",
        "    \"topic_id\": topics,\n",
        "    \"sentiment\": sentiments\n",
        "})\n",
        "\n",
        "# 6. Map topic ID to BERTopic label\n",
        "topic_label_map = {row[\"Topic\"]: row[\"Name\"] for _, row in topic_info.iterrows()}\n",
        "df[\"topic_label\"] = df[\"topic_id\"].map(topic_label_map)\n",
        "\n",
        "# 7. Aggregate strictness per topic\n",
        "agg = df.groupby([\"teacher\", \"topic_label\", \"sentiment\"]).size().unstack(fill_value=0)\n",
        "agg[\"total\"] = agg.sum(axis=1)\n",
        "agg[\"strict_ratio\"] = agg.get(\"strict\", 0) / agg[\"total\"]\n",
        "\n",
        "# 8. Display profile\n",
        "profile = agg.reset_index()[[\"teacher\", \"topic_label\", \"strict_ratio\"]]\n",
        "print(\"\\n=== Grading Style Profile ===\")\n",
        "print(profile)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "i6sBHmUlOAn9",
        "outputId": "f467c2e1-c3e2-4d7b-c2b2-7e3d539fd4d8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_reduce_dimensionality\u001b[0;34m(self, embeddings, y, partial_fit)\u001b[0m\n\u001b[1;32m   3775\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2816\u001b[0m             )\n\u001b[0;32m-> 2817\u001b[0;31m             self.embedding_, aux_data = self._fit_embed_data(\n\u001b[0m\u001b[1;32m   2818\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state, **kwargs)\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \"\"\"\n\u001b[0;32m-> 2865\u001b[0;31m         return simplicial_set_embedding(\n\u001b[0m\u001b[1;32m   2866\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spectral\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         embedding = spectral_layout(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36mspectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, tol, maxiter)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m     return _spectral_layout(\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36m_spectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, init, method, tol, maxiter)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigsh\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n\u001b[0m\u001b[1;32m    520\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             raise TypeError(\"Cannot use scipy.linalg.eigh for sparse A with \"\n\u001b[0m\u001b[1;32m   1607\u001b[0m                             \u001b[0;34m\"k >= N. Use scipy.linalg.eigh(A.toarray()) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b806889eea24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 2. Train BERTopic model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtopic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 3. Analyze topic labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# Reduce dimensionality and fit UMAP model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mumap_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce_dimensionality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# Zero-shot Topic Modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_reduce_dimensionality\u001b[0;34m(self, embeddings, y, partial_fit)\u001b[0m\n\u001b[1;32m   3776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3778\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m         \u001b[0mumap_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m             )\n\u001b[0;32m-> 2817\u001b[0;31m             self.embedding_, aux_data = self._fit_embed_data(\n\u001b[0m\u001b[1;32m   2818\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state, **kwargs)\u001b[0m\n\u001b[1;32m   2863\u001b[0m         \u001b[0mthrough\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \"\"\"\n\u001b[0;32m-> 2865\u001b[0;31m         return simplicial_set_embedding(\n\u001b[0m\u001b[1;32m   2866\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         )\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spectral\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         embedding = spectral_layout(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36mspectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, tol, maxiter)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mspectral\u001b[0m \u001b[0membedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m     return _spectral_layout(\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36m_spectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, init, method, tol, maxiter)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigsh\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n\u001b[0m\u001b[1;32m    520\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m             raise TypeError(\"Cannot use scipy.linalg.eigh for sparse A with \"\n\u001b[0m\u001b[1;32m   1607\u001b[0m                             \u001b[0;34m\"k >= N. Use scipy.linalg.eigh(A.toarray()) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m                             \" reduce k.\")\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def get_top_keywords(sentences, n=5):\n",
        "    words = []\n",
        "    for sent in sentences:\n",
        "        words += re.findall(r'\\b\\w+\\b', sent.lower())\n",
        "    most_common = Counter(words).most_common(n)\n",
        "    return [word for word, _ in most_common if word not in {\"the\", \"you\", \"and\", \"your\"}]\n",
        "\n",
        "for cluster_id in sorted(set(clusters)):\n",
        "    sents = df[df[\"cluster\"] == cluster_id][\"sentence\"].tolist()\n",
        "    keywords = get_top_keywords(sents)\n",
        "    print(f\"Topic {cluster_id}: {' / '.join(keywords)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r8V0tWiORwX",
        "outputId": "8e968ee9-b3e6-4b01-d631-f9a64826c172"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: of\n",
            "Topic 1: in / of / terms / task / accuracy\n",
            "Topic 2: discussion / dear / student\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "bnoA7EScaQvS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"grammar.csv\")\n",
        "\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Kj-63-NLaSgT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()"
      ],
      "metadata": {
        "id": "nqCM2pA5acnj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train_dense.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "sz50JrGaaq9_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tIICFBLObEK4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(X_train_dense, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvDBWlW0bLTY",
        "outputId": "0e05df4f-3890-44bd-cf28-083d6ca8aee5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 5.6247e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.5065e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.6341e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.4662e-04 - val_accuracy: 1.0000 - val_loss: 2.9670e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1977e-04 - val_accuracy: 1.0000 - val_loss: 2.4739e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.2600e-04 - val_accuracy: 1.0000 - val_loss: 2.0813e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6213e-04 - val_accuracy: 1.0000 - val_loss: 1.7411e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4912e-04 - val_accuracy: 1.0000 - val_loss: 1.5015e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8965e-04 - val_accuracy: 1.0000 - val_loss: 1.3075e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2103e-04 - val_accuracy: 1.0000 - val_loss: 1.1397e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_dense)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred_labels)\n",
        "cm = confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "print(f\"Accuracy: {acc}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MoAFpIqbUvs",
        "outputId": "b9c874c0-b2c0-48d3-bcb4-9a8f5a894013"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            "[[119   0]\n",
            " [  0 101]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lT2EkcpcbmTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQStf+TXFVOp68XMAmtXCh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3570a444f7cf4c72969271ac5502aa97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bb31ccd02ee4e948510b2afd6c273ed",
              "IPY_MODEL_414f851996ae437c842b7b77a3926499",
              "IPY_MODEL_a53b962e16af4a36b5721139ea4f7500"
            ],
            "layout": "IPY_MODEL_c83052d759734d41983f1b630ee4ed0c"
          }
        },
        "8bb31ccd02ee4e948510b2afd6c273ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bcf2e1fca744b9a5a8b3edcea45526",
            "placeholder": "​",
            "style": "IPY_MODEL_bd80390a86da48478ecd931482c1af79",
            "value": "Map: 100%"
          }
        },
        "414f851996ae437c842b7b77a3926499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e2d0ecbec34311aef19a5fc1265de4",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77454980332747b6ba7863133a697a2d",
            "value": 150
          }
        },
        "a53b962e16af4a36b5721139ea4f7500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df22dbe58803444596ff4182df6253f1",
            "placeholder": "​",
            "style": "IPY_MODEL_52dca939fa114d4780603b52516ee0de",
            "value": " 150/150 [00:00&lt;00:00, 402.71 examples/s]"
          }
        },
        "c83052d759734d41983f1b630ee4ed0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bcf2e1fca744b9a5a8b3edcea45526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd80390a86da48478ecd931482c1af79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92e2d0ecbec34311aef19a5fc1265de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77454980332747b6ba7863133a697a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df22dbe58803444596ff4182df6253f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52dca939fa114d4780603b52516ee0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae770935066141c4ac704dffd2086e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cccfaa3037a8456d9423b22d0d7e7b7e",
              "IPY_MODEL_dbf1516b704349e4aedb288e3d7a5299",
              "IPY_MODEL_29764b355ca44078bac81da3580839fc"
            ],
            "layout": "IPY_MODEL_23077d5107304ef5b8086d1e6e397614"
          }
        },
        "cccfaa3037a8456d9423b22d0d7e7b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57b713c537a48d7ab239b6992f03321",
            "placeholder": "​",
            "style": "IPY_MODEL_e8fe230242f249e9b24ad382af969e02",
            "value": "Map: 100%"
          }
        },
        "dbf1516b704349e4aedb288e3d7a5299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9beb26ed00cc4c68885cfea2c8380875",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_729a7e5303d14bfbb256df6b89777c6a",
            "value": 150
          }
        },
        "29764b355ca44078bac81da3580839fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4ad994092e492bb3c17457ce35bb28",
            "placeholder": "​",
            "style": "IPY_MODEL_5289f6c3cc05404dbecb72f809d50040",
            "value": " 150/150 [00:00&lt;00:00, 411.71 examples/s]"
          }
        },
        "23077d5107304ef5b8086d1e6e397614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57b713c537a48d7ab239b6992f03321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fe230242f249e9b24ad382af969e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9beb26ed00cc4c68885cfea2c8380875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729a7e5303d14bfbb256df6b89777c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be4ad994092e492bb3c17457ce35bb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5289f6c3cc05404dbecb72f809d50040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06c34ca65d974f9ca9efda8fa9d314e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_94e489f3e89d4c308b3faf53c847ff25"
          }
        },
        "95cc48355ed74d839495a06d8d271922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ea0991a9b14dd59c8b0a1ca44cbb22",
            "placeholder": "​",
            "style": "IPY_MODEL_35e4b2631c46449b8e316716a6b3d094",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1fea597f40f04c93ae911c36206d609b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8210ea0020d946379f7d29c5d3cc8356",
            "placeholder": "​",
            "style": "IPY_MODEL_ac4eaab3e6234a2bbe87e956004939ed",
            "value": ""
          }
        },
        "d4673fd5ef8541ad96beba7bdaf2d6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_79c333f457de40bc8c02f314ca23dca2",
            "style": "IPY_MODEL_6f16e50d02284fcaa08ed95a18d3aad9",
            "value": true
          }
        },
        "785b533be3624bb98d0e73acac97afea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ad08deb5f4a24f30a68e6fe39e254e78",
            "style": "IPY_MODEL_f0923694ad8c4090967ca25a0922c08f",
            "tooltip": ""
          }
        },
        "3e437c1c104648159ba50812b7efb49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc78b07800874dc8be704d81bcc7330b",
            "placeholder": "​",
            "style": "IPY_MODEL_34cecc6eb5814c55a16fc5f01ec3428e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "94e489f3e89d4c308b3faf53c847ff25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e1ea0991a9b14dd59c8b0a1ca44cbb22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e4b2631c46449b8e316716a6b3d094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8210ea0020d946379f7d29c5d3cc8356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4eaab3e6234a2bbe87e956004939ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79c333f457de40bc8c02f314ca23dca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f16e50d02284fcaa08ed95a18d3aad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad08deb5f4a24f30a68e6fe39e254e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0923694ad8c4090967ca25a0922c08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "bc78b07800874dc8be704d81bcc7330b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34cecc6eb5814c55a16fc5f01ec3428e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e065dc22c00a40639fd25236beed9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c8a659eb3348d093264f9728f40ce6",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d451f5aa1f48f1bb89f032ecd7caa1",
            "value": "Connecting..."
          }
        },
        "e5c8a659eb3348d093264f9728f40ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d451f5aa1f48f1bb89f032ecd7caa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}